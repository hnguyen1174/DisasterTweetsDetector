{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.4.2)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.56.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Installing the Huggingface's Transformers library\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-1.5.0-py3-none-any.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\n",
      "Collecting huggingface-hub<0.1.0\n",
      "  Downloading huggingface_hub-0.0.7-py3-none-any.whl (33 kB)\n",
      "Collecting tqdm<4.50.0,>=4.27\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 3.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.4.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.0.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: tqdm, xxhash, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.56.2\n",
      "    Uninstalling tqdm-4.56.2:\n",
      "      Successfully uninstalled tqdm-4.56.2\n",
      "Successfully installed datasets-1.5.0 huggingface-hub-0.0.7 tqdm-4.49.0 xxhash-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "\n",
    "# Utils\n",
    "import os                                       # Operating system operations\n",
    "import json                                     # Working with json file\n",
    "import re                                       # Regular expression\n",
    "import unicodedata                              # Unicode + regular expression\n",
    "import random                                   # Random\n",
    "import collections                              # Counter\n",
    "\n",
    "# Computation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "\n",
    "# Transformers\n",
    "import transformers\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ML utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction, naive_bayes, pipeline, manifold, preprocessing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Others\n",
    "from lime import lime_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/kaggle/input/nlp-getting-started'\n",
    "\n",
    "train = pd.read_csv(os.path.join(dirname, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(dirname, 'test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(dirname, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial observations:\n",
    "\n",
    "* Training set includes 7,613 tweets\n",
    "* 43% of the training set contains disaster tweets (signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target\n",
       "count   7613.000000  7613.00000\n",
       "mean    5441.934848     0.42966\n",
       "std     3137.116090     0.49506\n",
       "min        1.000000     0.00000\n",
       "25%     2734.000000     0.00000\n",
       "50%     5408.000000     0.00000\n",
       "75%     8146.000000     1.00000\n",
       "max    10873.000000     1.00000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    This function computes metrics for Transformers' fine tuning\n",
    "    \n",
    "    Args:\n",
    "        pred: predictions from Transformers' Trainer\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that contains metrics of interest for binary classification:\n",
    "            (1) Accuracy\n",
    "            (2) Precision\n",
    "            (3) Recall\n",
    "            (4) F1 Score\n",
    "            (5) AUC\n",
    "    \"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    \n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall, \"auc\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    \"\"\"\n",
    "    Tokenize by batches for Transformers\n",
    "    \"\"\"\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cuda_seed(seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: EAD and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_texts = train.text.to_list()\n",
    "all_train_labels = train.target.to_list()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    all_train_texts, all_train_labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3468, 1: 2622})\n",
      "Counter({0: 874, 1: 649})\n"
     ]
    }
   ],
   "source": [
    "# Let's see the distribution of labels in training and val set\n",
    "# They are pretty evenly distributed among two sets\n",
    "\n",
    "print(collections.Counter(train_labels))\n",
    "print(collections.Counter(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, \n",
    "                    flg_stemm=False, \n",
    "                    flg_lemm=True, \n",
    "                    lst_stopwords=None):\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    lst_text = text.split()\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "                            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n",
    "\n",
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how does\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \" u \": \" you \",\n",
    "    \" ur \": \" your \",\n",
    "    \" n \": \" and \",\n",
    "    \"won't\": \"would not\",\n",
    "    'dis': 'this',\n",
    "    'bak': 'back',\n",
    "    'brng': 'bring'\n",
    "}\n",
    "\n",
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def remove_emails(x):\n",
    "     return re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", x)\n",
    "\n",
    "\n",
    "def remove_urls(x):\n",
    "    return re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , x)\n",
    "\n",
    "def remove_rt(x):\n",
    "    return re.sub(r'\\brt\\b', '', x).strip()\n",
    "\n",
    "def remove_special_chars(x):\n",
    "    x = re.sub(r'[^\\w ]+', \"\", x)\n",
    "    x = ' '.join(x.split())\n",
    "    return x\n",
    "\n",
    "\n",
    "def remove_accented_chars(x):\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_clean'] = train['text'].apply(lambda x: cont_to_exp(x))\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: remove_emails(x))\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: remove_urls(x))\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: remove_rt(x))\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: remove_special_chars(x))\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: remove_accented_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text_clean\"] = train[\"text_clean\"].apply(lambda x: \n",
    "                                                preprocess_text(x, \n",
    "                                                                flg_stemm=True, \n",
    "                                                                flg_lemm=False,\n",
    "                                                                lst_stopwords=lst_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 peopl receiv wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "      <td>rockyfir updat california hwi 20 close direct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood thisast heavi rain caus flash flood stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "      <td>im top hill see fire wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "      <td>there emerg evacu happen build across street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "      <td>im afraid tornado come area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target                                         text_clean  \n",
       "0       1          deed reason earthquak may allah forgiv us  \n",
       "1       1               forest fire near la rong sask canada  \n",
       "2       1  resid ask shelter place notifi offic evacu she...  \n",
       "3       1  13000 peopl receiv wildfir evacu order california  \n",
       "4       1  got sent photo rubi alaska smoke wildfir pour ...  \n",
       "5       1  rockyfir updat california hwi 20 close direct ...  \n",
       "6       1  flood thisast heavi rain caus flash flood stre...  \n",
       "7       1                          im top hill see fire wood  \n",
       "8       1       there emerg evacu happen build across street  \n",
       "9       1                        im afraid tornado come area  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_processed = [cont_to_exp(text) for text in train_texts]\n",
    "train_texts_processed = [remove_emails(text) for text in train_texts_processed]\n",
    "train_texts_processed = [remove_urls(text) for text in train_texts_processed]\n",
    "train_texts_processed = [remove_rt(text) for text in train_texts_processed]\n",
    "train_texts_processed = [remove_special_chars(text) for text in train_texts_processed]\n",
    "train_texts_processed = [remove_accented_chars(text) for text in train_texts_processed]\n",
    "train_texts_processed = [preprocess_text(text,\n",
    "                                         flg_stemm=True, \n",
    "                                         flg_lemm=False,\n",
    "                                         lst_stopwords=lst_stopwords) for text in train_texts_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['courag honest analysi need use atom bomb 1945 hiroshima70 japanes militari refus surrend',\n",
       " 'zachzaidman 670thescor wld b shame golf cart becam engulf flame boycottbear',\n",
       " 'tell barackobama rescind medal honor given us soldier massacr wound knee sign amp rt',\n",
       " 'worri ca drought might affect extrem weather dampen economi',\n",
       " 'youngheroesid lava blast amp power red pantherattack jamilazzaini alifaditha',\n",
       " 'wreckag conclus confirm mh370 malaysia pm investig famili',\n",
       " 'builder dental emerg ruin plan emot blackmail afternoon bump',\n",
       " 'bmx issu areal flood advisori shelbi al till aug 5 900 pm cdt',\n",
       " '360wisenew china stock market crash gem rubbl',\n",
       " 'robertoneill31 get hit foul ball sit hardli freak accid war zone']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_processed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts_processed = [cont_to_exp(text) for text in val_texts]\n",
    "val_texts_processed = [remove_emails(text) for text in val_texts_processed]\n",
    "val_texts_processed = [remove_urls(text) for text in val_texts_processed]\n",
    "val_texts_processed = [remove_rt(text) for text in val_texts_processed]\n",
    "val_texts_processed = [remove_special_chars(text) for text in val_texts_processed]\n",
    "val_texts_processed = [remove_accented_chars(text) for text in val_texts_processed]\n",
    "val_texts_processed = [preprocess_text(text,\n",
    "                                       flg_stemm=True, \n",
    "                                       flg_lemm=False,\n",
    "                                       lst_stopwords=lst_stopwords) for text in val_texts_processed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also interested in the common features of a text-based dataset such as:\n",
    "\n",
    "1. Word counts -- this is especially important because the BERT and related models can only take ~ 512 tokens per document.\n",
    "2. Simple character count\n",
    "3. Hashtag count\n",
    "4. Mention count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(x):\n",
    "    length = len(str(x).split())\n",
    "    return length\n",
    "\n",
    "def charcount(x):\n",
    "    s = x.split()\n",
    "    x = ''.join(s)\n",
    "    return len(x)\n",
    "\n",
    "def hashtagcount(x):\n",
    "    l = len([t for t in x.split() if t.startswith('#')])\n",
    "    return l\n",
    "\n",
    "def mentionscount(x):\n",
    "    l = len([t for t in x.split() if t.startswith('@')])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_count = [charcount(text) for text in train_texts]\n",
    "word_count = [wordcount(text) for text in train_texts]\n",
    "hashtag_count = [hashtagcount(text) for text in train_texts]\n",
    "mention_count = [mentionscount(text) for text in train_texts]\n",
    "text_len = [len(text) for text in train_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of features such as character count, word count, hashtag count, mention count, length, stratified by target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['char_count'] = train['text'].apply(lambda x: charcount(x))\n",
    "train['word_count'] = train['text'].apply(lambda x: wordcount(x))\n",
    "train['hashtag_count'] = train['text'].apply(lambda x: hashtagcount(x))\n",
    "train['mention_count'] = train['text'].apply(lambda x: mentionscount(x))\n",
    "train['length'] = train['text'].apply(len)\n",
    "\n",
    "test['char_count'] = test['text'].apply(lambda x: charcount(x))\n",
    "test['word_count'] = test['text'].apply(lambda x: wordcount(x))\n",
    "test['hashtag_count'] = test['text'].apply(lambda x: hashtagcount(x))\n",
    "test['mention_count'] = test['text'].apply(lambda x: mentionscount(x))\n",
    "test['length'] = test['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f7db7b85ad0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 726.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preliminary finding: the tweets that are classified as disaster tweets\n",
    "# are usually longer.\n",
    "\n",
    "plt.figure(figsize = (8, 10))\n",
    "sns.displot(data=train,\n",
    "            x='length', \n",
    "            hue='target', \n",
    "            kde=True,\n",
    "            bins=20, \n",
    "            height=5, \n",
    "            aspect=1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f7db75c9ad0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 726.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 10))\n",
    "sns.displot(data=train,\n",
    "            kind='hist', \n",
    "            x='hashtag_count', \n",
    "            hue='target', \n",
    "            kde=True,\n",
    "            bins=20,\n",
    "            height=5, \n",
    "            aspect=1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f7db72c4410>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 726.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8, 10))\n",
    "sns.displot(data=train,\n",
    "            kind='hist', \n",
    "            x='word_count', \n",
    "            hue='target', \n",
    "            kde=True,\n",
    "            bins=20,\n",
    "            height=5, \n",
    "            aspect=1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping track of all performances:\n",
    "\n",
    "|Model|Text-Preprocessing|Accuracy|Precision|Recall|F1|AUC|\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|Dummy|N/A|57.38%|0.00%|0.00%|0.00%|50.00%|\n",
    "|Logistic Regression|No Preprocessing|79.58%|78.84%|71.19%|74.82%|78.50%|\n",
    "|Logistic Regression|Preprocessing|78.99%|79.64%|68.10%|73.42%|77.59%|\n",
    "|SVC|No Preprocessing|77.41%|89.41%|53.31%|66.80%|74.31%|\n",
    "|SVC|Preprocessing|77.74%|88.37%|55.00%|67.81%|74.81%|\n",
    "|Random Forest|No Preprocessing|65.20%|97.60%|18.79%|31.52%|59.22%|\n",
    "|Random Forest|Preprocessing|64.28%|99.07%|16.33%|28.04%|58.11%|\n",
    "|BERT-Base (e=2, alternate b)|No Preprocessing|84.63%|87.25%|74.88%|80.60%|83.38%|\n",
    "|BERT-Base (e=1, b=32)|No Preprocessing|82.73%|82.06%|76.11%|78.98%|81.88%|\n",
    "|BERT-Base (e=2, b=64)|No Preprocessing|82.14%|78.26%|80.43%|79.33%|81.92%|\n",
    "|DistillBERT-Base (e=2, b=16)|No Preprocessing|84.18%|84.69%|76.73%|80.52%|83.22%|\n",
    "|DistillBERT-Base (e=1, b=32)|No Preprocessing|82.47%|82.93%|74.11%|78.28%|81.39%|\n",
    "|DistillBERT-Base (e=5, b=64)|No Preprocessing|82.07%|82.19%|73.96%|77.88%|81.03%|\n",
    "|RoBERTa-Base (e=2, b=16)|No Preprocessing|83.32%|80.91%|79.66%|80.28%|82.85%|\n",
    "|RoBERTa-Base (e=2, b=32)|No Preprocessing|82.53%|81.14%|76.88%|78.96%|81.81%|\n",
    "|RoBERTa-Base (e=1, b=64)|No Preprocessing|81.88%|79.00%|78.27%|78.64%|81.41%|\n",
    "|RoBERTa-Base (e=2, alternate b)|No Preprocessing|82.40%|78.91%|80.12%|79.51%|82.11%|\n",
    "|XLM-RoBERTa-Base (e=2, b=16)|No Preprocessing|82.14%|80.95%|75.96%|78.38%|81.34%|\n",
    "|XLM-RoBERTa-Base (e=2, b=32)|No Preprocessing|82.14%|82.11%|74.27%|77.99%|81.13%|\n",
    "|XLM-RoBERTa-Base (e=1, b=64)|No Preprocessing|81.88%|79.00%|78.27%|78.38%|81.41%|\n",
    "|XLM-RoBERTa-Base (e=5, alternate b)|No Preprocessing|81.35%|78.03%|78.27%|78.15%|80.96%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 1 - Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dummy baseline achieves an accuracy of **57.39%** and F1-Score of **0.00%**.\n",
    "\n",
    "There should be no difference in the performance of dummy baseline for processed and non-processed texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5738673670387393,\n",
       " 'f1': 0.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'auc': 0.5}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf(data):\n",
    "    \"\"\"\n",
    "    Function creates a tfidf tokenized training set and associated vectorizer for test data.\n",
    "\n",
    "    Args:\n",
    "        data (list): Training data to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        list: The edited training data.\n",
    "        tfidf_vectorizer: tfidf vectorizer to be applied to test data.\n",
    "    \"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    train = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "    return train, tfidf_vectorizer\n",
    "\n",
    "def compute_metrics_baseline(labels, preds):    \n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    \n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall, \"auc\": auc}\n",
    "\n",
    "train_tfidf, tfidf_vectorizer = tfidf(train_texts)\n",
    "val_tfidf = tfidf_vectorizer.transform(val_texts)\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(train_tfidf, train_labels)\n",
    "\n",
    "val_preds = dummy_clf.predict(val_tfidf)\n",
    "\n",
    "compute_metrics_baseline(val_labels, val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression baseline (with TF-IDF transformation) achieves an accuracy of **79.58%** and F1-Score of **74.82%**. This is quite significant.\n",
    "\n",
    "Fitting into the common theme, text processing actually **decreases** performance of the Logistic regression baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7957977675640184,\n",
       " 'f1': 0.748178137651822,\n",
       " 'precision': 0.78839590443686,\n",
       " 'recall': 0.711864406779661,\n",
       " 'auc': 0.7849939882868557}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_clf = LogisticRegression(random_state=0).fit(train_tfidf, train_labels)\n",
    "val_preds = logreg_clf.predict(val_tfidf)\n",
    "\n",
    "compute_metrics_baseline(val_labels, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7898883782009193,\n",
       " 'f1': 0.7342192691029902,\n",
       " 'precision': 0.7963963963963964,\n",
       " 'recall': 0.6810477657935285,\n",
       " 'auc': 0.7758785739722791}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf_prc, tfidf_vectorizer = tfidf(train_texts_processed)\n",
    "val_tfidf_prc = tfidf_vectorizer.transform(val_texts_processed)\n",
    "\n",
    "logreg_clf_prc = LogisticRegression(random_state=0).fit(train_tfidf_prc, train_labels)\n",
    "val_preds_prc = logreg_clf_prc.predict(val_tfidf_prc)\n",
    "\n",
    "compute_metrics_baseline(val_labels, val_preds_prc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 3 - SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SVC baseline (with TF-IDF transformation) achieves an accuracy of **77.41%** and F1-Score of **66.80%**. This is quite significant.\n",
    "\n",
    "Text Processing doesn't seem to matter in the case of SVC. Text processing achieves very little improvements in metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7741300065659882,\n",
       " 'f1': 0.667953667953668,\n",
       " 'precision': 0.8940568475452196,\n",
       " 'recall': 0.5331278890600925,\n",
       " 'auc': 0.7431085669556755}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "svc_clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto')).fit(train_tfidf, train_labels)\n",
    "val_preds = svc_clf.predict(val_tfidf)\n",
    "\n",
    "compute_metrics_baseline(val_labels, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7774130006565988,\n",
       " 'f1': 0.6780626780626781,\n",
       " 'precision': 0.8836633663366337,\n",
       " 'recall': 0.5500770416024653,\n",
       " 'auc': 0.7481506489476858}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = make_pipeline(StandardScaler(with_mean=False), \n",
    "                        SVC(gamma='auto')).fit(train_tfidf_prc, train_labels)\n",
    "val_preds_prc = svc_clf.predict(val_tfidf_prc)\n",
    "\n",
    "compute_metrics_baseline(val_labels, val_preds_prc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 4 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6520026263952725,\n",
       " 'f1': 0.31524547803617575,\n",
       " 'precision': 0.976,\n",
       " 'recall': 0.18798151001540833,\n",
       " 'auc': 0.5922745078681161}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=10, \n",
    "                                min_samples_split=3,\n",
    "                                random_state=42)\n",
    "rf_clf.fit(train_tfidf, train_labels)\n",
    "\n",
    "val_preds = rf_clf.predict(val_tfidf)\n",
    "\n",
    "compute_metrics_baseline(val_labels, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6428102429415627,\n",
       " 'f1': 0.2804232804232804,\n",
       " 'precision': 0.9906542056074766,\n",
       " 'recall': 0.1633281972265023,\n",
       " 'auc': 0.5810920162333885}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth=10, \n",
    "                                min_samples_split=3,\n",
    "                                random_state=42)\n",
    "rf_clf.fit(train_tfidf_prc, train_labels)\n",
    "\n",
    "val_preds_prc = rf_clf.predict(val_tfidf_prc)\n",
    "\n",
    "compute_metrics_baseline(val_labels, val_preds_prc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Apply the Transformers models without any preprocessing to see if pre-processing add any benefits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, I prepare the dataset for Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(list(zip(train_texts, train_labels)),\n",
    "                        columns =['text', 'label'])\n",
    "\n",
    "val_df = pd.DataFrame(list(zip(val_texts, val_labels)),\n",
    "                      columns =['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-fffba8e3d1829887/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-fffba8e3d1829887/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "data_path = '/kaggle/working/data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "train_df.to_csv(os.path.join(data_path, 'train_df.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(data_path, 'val_df.csv'), index=False)\n",
    "\n",
    "tweets_dataset = load_dataset('csv', data_files={'train': os.path.join(data_path, 'train_df.csv'),\n",
    "                                                 'validation': os.path.join(data_path, 'val_df.csv')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prc_df = pd.DataFrame(list(zip(train_texts_processed, train_labels)),\n",
    "                            columns =['text', 'label'])\n",
    "\n",
    "val_prc_df = pd.DataFrame(list(zip(val_texts_processed, val_labels)),\n",
    "                          columns =['text', 'label'])\n",
    "\n",
    "train_prc_df.to_csv(os.path.join(data_path, 'train_prc_df.csv'), index=False)\n",
    "val_prc_df.to_csv(os.path.join(data_path, 'val_prc_df.csv'), index=False)\n",
    "\n",
    "tweets_dataset_prc = load_dataset('csv', data_files={'train': os.path.join(data_path, \n",
    "                                                                           'train_prc_df.csv'),\n",
    "                                                     'validation': os.path.join(data_path, \n",
    "                                                                                'val_prc_df.csv')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_dataset_prc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - BERT-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a87f8a66fc4d4ab7b0f1580c48aa88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc3d0ea9dd24243983b291448f83f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e2e6cca69e42a3a6378b100af046b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f40caab90d49ae9129f015af88a084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051aae573a574a0e97752ebe5c9c2aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1cec849bbd46b6a76891e3a160a11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7a83cdb9d847ca9758a71b93fc7358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'bert-base-uncased'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 06:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.416669</td>\n",
       "      <td>0.827315</td>\n",
       "      <td>0.800304</td>\n",
       "      <td>0.788922</td>\n",
       "      <td>0.812018</td>\n",
       "      <td>0.825346</td>\n",
       "      <td>3.084300</td>\n",
       "      <td>493.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316600</td>\n",
       "      <td>0.387641</td>\n",
       "      <td>0.846356</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.872531</td>\n",
       "      <td>0.748844</td>\n",
       "      <td>0.833804</td>\n",
       "      <td>3.087000</td>\n",
       "      <td>493.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295600</td>\n",
       "      <td>0.572545</td>\n",
       "      <td>0.816809</td>\n",
       "      <td>0.790383</td>\n",
       "      <td>0.771261</td>\n",
       "      <td>0.810478</td>\n",
       "      <td>0.815994</td>\n",
       "      <td>3.078700</td>\n",
       "      <td>494.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.747886</td>\n",
       "      <td>0.803020</td>\n",
       "      <td>0.780059</td>\n",
       "      <td>0.744056</td>\n",
       "      <td>0.819723</td>\n",
       "      <td>0.805170</td>\n",
       "      <td>3.083900</td>\n",
       "      <td>493.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.876141</td>\n",
       "      <td>0.825345</td>\n",
       "      <td>0.793157</td>\n",
       "      <td>0.800628</td>\n",
       "      <td>0.785824</td>\n",
       "      <td>0.820258</td>\n",
       "      <td>3.080200</td>\n",
       "      <td>494.452000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.26997736913794923, metrics={'train_runtime': 410.5993, 'train_samples_per_second': 4.64, 'total_flos': 1680225644210400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 9678011, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 569258, 'train_mem_gpu_alloc_delta': 1340402176, 'train_mem_cpu_peaked_delta': 188968650, 'train_mem_gpu_peaked_delta': 1086459392})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 04:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.907389</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.790801</td>\n",
       "      <td>0.762518</td>\n",
       "      <td>0.821263</td>\n",
       "      <td>0.815666</td>\n",
       "      <td>3.079100</td>\n",
       "      <td>494.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.904109</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.804314</td>\n",
       "      <td>0.819205</td>\n",
       "      <td>3.077600</td>\n",
       "      <td>494.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.863281</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>0.780635</td>\n",
       "      <td>0.766716</td>\n",
       "      <td>0.795069</td>\n",
       "      <td>0.807718</td>\n",
       "      <td>3.085100</td>\n",
       "      <td>493.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.138878</td>\n",
       "      <td>0.803677</td>\n",
       "      <td>0.780309</td>\n",
       "      <td>0.745787</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.805544</td>\n",
       "      <td>3.081800</td>\n",
       "      <td>494.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>1.426673</td>\n",
       "      <td>0.774787</td>\n",
       "      <td>0.764907</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.859784</td>\n",
       "      <td>0.785727</td>\n",
       "      <td>3.081400</td>\n",
       "      <td>494.257000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.05579450475051999, metrics={'train_runtime': 278.9427, 'train_samples_per_second': 1.721, 'total_flos': 1680225644210400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58813, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 237428, 'train_mem_gpu_alloc_delta': 885629952, 'train_mem_cpu_peaked_delta': 795662, 'train_mem_gpu_peaked_delta': 4271417344})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_cuda_seed()\n",
    "\n",
    "training_args.per_device_train_batch_size = 64\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 05:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>1.036262</td>\n",
       "      <td>0.827315</td>\n",
       "      <td>0.789768</td>\n",
       "      <td>0.820598</td>\n",
       "      <td>0.761171</td>\n",
       "      <td>0.818801</td>\n",
       "      <td>3.079200</td>\n",
       "      <td>494.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.972484</td>\n",
       "      <td>0.825345</td>\n",
       "      <td>0.796636</td>\n",
       "      <td>0.790592</td>\n",
       "      <td>0.802773</td>\n",
       "      <td>0.822439</td>\n",
       "      <td>3.081800</td>\n",
       "      <td>494.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.760502</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.780031</td>\n",
       "      <td>0.789889</td>\n",
       "      <td>0.770416</td>\n",
       "      <td>0.809121</td>\n",
       "      <td>3.085900</td>\n",
       "      <td>493.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>1.174758</td>\n",
       "      <td>0.810243</td>\n",
       "      <td>0.778883</td>\n",
       "      <td>0.773556</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>0.806901</td>\n",
       "      <td>3.082000</td>\n",
       "      <td>494.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>1.179735</td>\n",
       "      <td>0.812213</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.808023</td>\n",
       "      <td>3.079900</td>\n",
       "      <td>494.491000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.05172657657668229, metrics={'train_runtime': 338.1404, 'train_samples_per_second': 2.824, 'total_flos': 1680225644210400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59357, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 246839, 'train_mem_gpu_alloc_delta': 905028608, 'train_mem_cpu_peaked_delta': 188510082, 'train_mem_gpu_peaked_delta': 2135981056})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_cuda_seed()\n",
    "\n",
    "training_args.per_device_train_batch_size = 32\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - DistillBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d63be0a23c74cc685153ba273751e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8652a93f794649863efd3baaccad36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0add4535434047b9ab0b6b2cdecad4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74a61037dd34955b986ef2762614a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4e328de60547a894039dda990dd07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca6b4673ccb45ef9889369b3b89519d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99dd5566a45436d86ab401aa9309176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_name = 'distilbert-base-uncased'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 03:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.380700</td>\n",
       "      <td>0.507931</td>\n",
       "      <td>0.803020</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.734859</td>\n",
       "      <td>0.841294</td>\n",
       "      <td>0.807947</td>\n",
       "      <td>1.556300</td>\n",
       "      <td>978.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.278200</td>\n",
       "      <td>0.395182</td>\n",
       "      <td>0.841760</td>\n",
       "      <td>0.805174</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.767334</td>\n",
       "      <td>0.832180</td>\n",
       "      <td>1.557800</td>\n",
       "      <td>977.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.574364</td>\n",
       "      <td>0.827971</td>\n",
       "      <td>0.798462</td>\n",
       "      <td>0.797235</td>\n",
       "      <td>0.799692</td>\n",
       "      <td>0.824331</td>\n",
       "      <td>1.568400</td>\n",
       "      <td>971.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.712767</td>\n",
       "      <td>0.804334</td>\n",
       "      <td>0.774584</td>\n",
       "      <td>0.760773</td>\n",
       "      <td>0.788906</td>\n",
       "      <td>0.802348</td>\n",
       "      <td>1.562800</td>\n",
       "      <td>974.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.791628</td>\n",
       "      <td>0.818122</td>\n",
       "      <td>0.784771</td>\n",
       "      <td>0.791536</td>\n",
       "      <td>0.778120</td>\n",
       "      <td>0.812973</td>\n",
       "      <td>1.556600</td>\n",
       "      <td>978.446000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.2651575835749233, metrics={'train_runtime': 213.6676, 'train_samples_per_second': 8.916, 'total_flos': 1027545147468000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59742, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 841108, 'train_mem_gpu_alloc_delta': 820108800, 'train_mem_cpu_peaked_delta': 187914190, 'train_mem_gpu_peaked_delta': 551442432})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 02:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.819487</td>\n",
       "      <td>0.824688</td>\n",
       "      <td>0.782750</td>\n",
       "      <td>0.829310</td>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.813934</td>\n",
       "      <td>1.625900</td>\n",
       "      <td>936.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.944394</td>\n",
       "      <td>0.806303</td>\n",
       "      <td>0.779357</td>\n",
       "      <td>0.757267</td>\n",
       "      <td>0.802773</td>\n",
       "      <td>0.805849</td>\n",
       "      <td>1.617900</td>\n",
       "      <td>941.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.972720</td>\n",
       "      <td>0.798424</td>\n",
       "      <td>0.777052</td>\n",
       "      <td>0.734890</td>\n",
       "      <td>0.824345</td>\n",
       "      <td>0.801761</td>\n",
       "      <td>1.618800</td>\n",
       "      <td>940.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>1.099330</td>\n",
       "      <td>0.808930</td>\n",
       "      <td>0.780045</td>\n",
       "      <td>0.765579</td>\n",
       "      <td>0.795069</td>\n",
       "      <td>0.807146</td>\n",
       "      <td>1.616800</td>\n",
       "      <td>941.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>1.159797</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.782875</td>\n",
       "      <td>0.776935</td>\n",
       "      <td>0.788906</td>\n",
       "      <td>0.810357</td>\n",
       "      <td>1.617100</td>\n",
       "      <td>941.808000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.05833371663904939, metrics={'train_runtime': 176.7441, 'train_samples_per_second': 5.403, 'total_flos': 1027545147468000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 60421, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 205769, 'train_mem_gpu_alloc_delta': 550897664, 'train_mem_cpu_peaked_delta': 188262246, 'train_mem_gpu_peaked_delta': 1086212096})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTILLBERT, batch size = 32\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args.per_device_train_batch_size = 32\n",
    "training_args.per_device_eval_batch_size = 32\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 02:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>1.202012</td>\n",
       "      <td>0.816809</td>\n",
       "      <td>0.783888</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.812027</td>\n",
       "      <td>1.559900</td>\n",
       "      <td>976.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>1.220691</td>\n",
       "      <td>0.806960</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.766917</td>\n",
       "      <td>0.785824</td>\n",
       "      <td>0.804239</td>\n",
       "      <td>1.554000</td>\n",
       "      <td>980.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>1.259334</td>\n",
       "      <td>0.799737</td>\n",
       "      <td>0.769114</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.782743</td>\n",
       "      <td>0.797550</td>\n",
       "      <td>1.564000</td>\n",
       "      <td>973.777000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>1.246407</td>\n",
       "      <td>0.774787</td>\n",
       "      <td>0.754122</td>\n",
       "      <td>0.705094</td>\n",
       "      <td>0.810478</td>\n",
       "      <td>0.779381</td>\n",
       "      <td>1.555400</td>\n",
       "      <td>979.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.113085</td>\n",
       "      <td>0.820749</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.739599</td>\n",
       "      <td>0.810303</td>\n",
       "      <td>1.554500</td>\n",
       "      <td>979.721000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.026399738714098932, metrics={'train_runtime': 143.8992, 'train_samples_per_second': 3.336, 'total_flos': 1027545147468000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59309, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 179917, 'train_mem_gpu_alloc_delta': 541198336, 'train_mem_cpu_peaked_delta': 675035, 'train_mem_gpu_peaked_delta': 2166563840})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTILLBERT, batch size = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 - RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c38209f6674a04ab0a243f4ba4d203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d7c7c414704ce08ae6d23589ec6cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5129468b9e34d5e9eebfbaf312ce0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e04259342f4ebd96820f1f87e16a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f602630d48454eb059b6fe073ba79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e61fc0885f496b912ce0c70b3d9e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2377a3c655f64a10a2a6fbbf77960a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_name = 'roberta-base'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 06:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.477525</td>\n",
       "      <td>0.806960</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.757620</td>\n",
       "      <td>0.804314</td>\n",
       "      <td>0.806619</td>\n",
       "      <td>3.976400</td>\n",
       "      <td>383.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.425982</td>\n",
       "      <td>0.833224</td>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.809077</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.828511</td>\n",
       "      <td>3.962100</td>\n",
       "      <td>384.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.600532</td>\n",
       "      <td>0.828628</td>\n",
       "      <td>0.795294</td>\n",
       "      <td>0.809904</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.822523</td>\n",
       "      <td>3.971400</td>\n",
       "      <td>383.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.547375</td>\n",
       "      <td>0.822718</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.784962</td>\n",
       "      <td>0.804314</td>\n",
       "      <td>0.820349</td>\n",
       "      <td>3.988800</td>\n",
       "      <td>381.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.701739</td>\n",
       "      <td>0.828628</td>\n",
       "      <td>0.794973</td>\n",
       "      <td>0.810897</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.822325</td>\n",
       "      <td>3.977700</td>\n",
       "      <td>382.883000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.33196449965003905, metrics={'train_runtime': 416.9695, 'train_samples_per_second': 4.569, 'total_flos': 1935708226515000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58302, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 298501, 'train_mem_gpu_alloc_delta': 1523687936, 'train_mem_cpu_peaked_delta': 310228715, 'train_mem_gpu_peaked_delta': 1086190592})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 05:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.731773</td>\n",
       "      <td>0.823375</td>\n",
       "      <td>0.790987</td>\n",
       "      <td>0.797806</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>0.818343</td>\n",
       "      <td>4.178300</td>\n",
       "      <td>364.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.631275</td>\n",
       "      <td>0.825345</td>\n",
       "      <td>0.789557</td>\n",
       "      <td>0.811382</td>\n",
       "      <td>0.768875</td>\n",
       "      <td>0.818076</td>\n",
       "      <td>4.180300</td>\n",
       "      <td>364.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.623328</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.779160</td>\n",
       "      <td>0.786499</td>\n",
       "      <td>0.771957</td>\n",
       "      <td>0.808175</td>\n",
       "      <td>4.179100</td>\n",
       "      <td>364.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.874345</td>\n",
       "      <td>0.797768</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>0.742532</td>\n",
       "      <td>0.804314</td>\n",
       "      <td>0.798610</td>\n",
       "      <td>4.175200</td>\n",
       "      <td>364.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.914742</td>\n",
       "      <td>0.823375</td>\n",
       "      <td>0.788688</td>\n",
       "      <td>0.804487</td>\n",
       "      <td>0.773498</td>\n",
       "      <td>0.816955</td>\n",
       "      <td>4.173800</td>\n",
       "      <td>364.894000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.13189124440023411, metrics={'train_runtime': 351.4267, 'train_samples_per_second': 2.717, 'total_flos': 1935708226515000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58517, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 254973, 'train_mem_gpu_alloc_delta': 1031469056, 'train_mem_cpu_peaked_delta': 309836290, 'train_mem_gpu_peaked_delta': 2154615808})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROBERTA, batch size = 32\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 04:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.966888</td>\n",
       "      <td>0.818779</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.790047</td>\n",
       "      <td>0.782743</td>\n",
       "      <td>0.814140</td>\n",
       "      <td>3.158000</td>\n",
       "      <td>482.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>1.251126</td>\n",
       "      <td>0.779383</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.697851</td>\n",
       "      <td>0.850539</td>\n",
       "      <td>0.788542</td>\n",
       "      <td>3.162100</td>\n",
       "      <td>481.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>1.128682</td>\n",
       "      <td>0.786605</td>\n",
       "      <td>0.766691</td>\n",
       "      <td>0.717742</td>\n",
       "      <td>0.822804</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>3.154700</td>\n",
       "      <td>482.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.891254</td>\n",
       "      <td>0.816809</td>\n",
       "      <td>0.784888</td>\n",
       "      <td>0.785494</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>0.812622</td>\n",
       "      <td>3.168700</td>\n",
       "      <td>480.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.902372</td>\n",
       "      <td>0.810900</td>\n",
       "      <td>0.781487</td>\n",
       "      <td>0.769806</td>\n",
       "      <td>0.793529</td>\n",
       "      <td>0.808664</td>\n",
       "      <td>3.158400</td>\n",
       "      <td>482.210000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.06769063311318556, metrics={'train_runtime': 282.6269, 'train_samples_per_second': 1.698, 'total_flos': 1935708226515000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58429, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 234070, 'train_mem_gpu_alloc_delta': 1010759680, 'train_mem_cpu_peaked_delta': 725770, 'train_mem_gpu_peaked_delta': 4328633344})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROBERTA, batch size = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 06:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>1.200747</td>\n",
       "      <td>0.797768</td>\n",
       "      <td>0.776488</td>\n",
       "      <td>0.733882</td>\n",
       "      <td>0.824345</td>\n",
       "      <td>0.801189</td>\n",
       "      <td>3.158500</td>\n",
       "      <td>482.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.998626</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>0.772370</td>\n",
       "      <td>0.787200</td>\n",
       "      <td>0.758089</td>\n",
       "      <td>0.802958</td>\n",
       "      <td>3.155500</td>\n",
       "      <td>482.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.869788</td>\n",
       "      <td>0.824032</td>\n",
       "      <td>0.795107</td>\n",
       "      <td>0.789074</td>\n",
       "      <td>0.801233</td>\n",
       "      <td>0.821097</td>\n",
       "      <td>3.154100</td>\n",
       "      <td>482.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>0.823375</td>\n",
       "      <td>0.788688</td>\n",
       "      <td>0.804487</td>\n",
       "      <td>0.773498</td>\n",
       "      <td>0.816955</td>\n",
       "      <td>3.159900</td>\n",
       "      <td>481.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>1.106576</td>\n",
       "      <td>0.816152</td>\n",
       "      <td>0.786585</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.795069</td>\n",
       "      <td>0.813439</td>\n",
       "      <td>3.154700</td>\n",
       "      <td>482.771000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.08791634191433824, metrics={'train_runtime': 409.7328, 'train_samples_per_second': 4.649, 'total_flos': 1935708226515000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58445, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 288997, 'train_mem_gpu_alloc_delta': 1010759680, 'train_mem_cpu_peaked_delta': 310165511, 'train_mem_gpu_peaked_delta': 1087050752})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROBERTA, train batch size = 16; eval batch size = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = 16\n",
    "training_args.per_device_eval_batch_size = 64\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 - XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e0d0ec11df4bb1909788a87d467153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbd348d24014616a758d5b7ebeaac4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6840d074286349c0a421a76d6ad00503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa8a9187b634e0589ef6a12c1b44502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3c7f1d2a5b4ea3bae8a3acd6f50e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3b5142394c4b4a838274889efdaf4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_name = 'xlm-roberta-base'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 09:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>0.450621</td>\n",
       "      <td>0.816152</td>\n",
       "      <td>0.777070</td>\n",
       "      <td>0.803954</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>0.807885</td>\n",
       "      <td>4.005200</td>\n",
       "      <td>380.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.361100</td>\n",
       "      <td>0.439926</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.813454</td>\n",
       "      <td>4.010300</td>\n",
       "      <td>379.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.436134</td>\n",
       "      <td>0.814839</td>\n",
       "      <td>0.777953</td>\n",
       "      <td>0.795491</td>\n",
       "      <td>0.761171</td>\n",
       "      <td>0.807931</td>\n",
       "      <td>3.982500</td>\n",
       "      <td>382.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.521849</td>\n",
       "      <td>0.808273</td>\n",
       "      <td>0.779123</td>\n",
       "      <td>0.765230</td>\n",
       "      <td>0.793529</td>\n",
       "      <td>0.806375</td>\n",
       "      <td>3.985400</td>\n",
       "      <td>382.149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.612607</td>\n",
       "      <td>0.811556</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790997</td>\n",
       "      <td>0.758089</td>\n",
       "      <td>0.804674</td>\n",
       "      <td>3.989600</td>\n",
       "      <td>381.739000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.4139234228084094, metrics={'train_runtime': 553.5878, 'train_samples_per_second': 3.441, 'total_flos': 5181483259184400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 62050, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 285981, 'train_mem_gpu_alloc_delta': 3349812736, 'train_mem_cpu_peaked_delta': 1537414598, 'train_mem_gpu_peaked_delta': 1371959296})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, BATCH SIZE = 16\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 06:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.583737</td>\n",
       "      <td>0.803020</td>\n",
       "      <td>0.771341</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.800014</td>\n",
       "      <td>4.185000</td>\n",
       "      <td>363.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.536577</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>0.821124</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>0.811272</td>\n",
       "      <td>4.185100</td>\n",
       "      <td>363.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.528237</td>\n",
       "      <td>0.812213</td>\n",
       "      <td>0.767480</td>\n",
       "      <td>0.812392</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.801279</td>\n",
       "      <td>4.188800</td>\n",
       "      <td>363.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.757559</td>\n",
       "      <td>0.776100</td>\n",
       "      <td>0.759011</td>\n",
       "      <td>0.701044</td>\n",
       "      <td>0.827427</td>\n",
       "      <td>0.782707</td>\n",
       "      <td>4.190100</td>\n",
       "      <td>363.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.841930</td>\n",
       "      <td>0.797768</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.755622</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>0.795040</td>\n",
       "      <td>4.189400</td>\n",
       "      <td>363.533000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.19334270779375007, metrics={'train_runtime': 400.1556, 'train_samples_per_second': 2.387, 'total_flos': 5181483259184400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58277, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 253998, 'train_mem_gpu_alloc_delta': 2232875008, 'train_mem_cpu_peaked_delta': 1537022439, 'train_mem_gpu_peaked_delta': 2713649152})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, batch size = 32\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 05:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.821001</td>\n",
       "      <td>0.795141</td>\n",
       "      <td>0.765414</td>\n",
       "      <td>0.747430</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>0.793744</td>\n",
       "      <td>3.641800</td>\n",
       "      <td>418.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.784763</td>\n",
       "      <td>0.793171</td>\n",
       "      <td>0.760820</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771957</td>\n",
       "      <td>0.790441</td>\n",
       "      <td>3.640100</td>\n",
       "      <td>418.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.804334</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.785824</td>\n",
       "      <td>0.801951</td>\n",
       "      <td>3.646000</td>\n",
       "      <td>417.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>0.934015</td>\n",
       "      <td>0.782009</td>\n",
       "      <td>0.765867</td>\n",
       "      <td>0.706112</td>\n",
       "      <td>0.836672</td>\n",
       "      <td>0.789045</td>\n",
       "      <td>3.651900</td>\n",
       "      <td>417.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.199600</td>\n",
       "      <td>0.854983</td>\n",
       "      <td>0.783979</td>\n",
       "      <td>0.757196</td>\n",
       "      <td>0.726629</td>\n",
       "      <td>0.790447</td>\n",
       "      <td>0.784812</td>\n",
       "      <td>3.651100</td>\n",
       "      <td>417.133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.10278550858298938, metrics={'train_runtime': 330.9366, 'train_samples_per_second': 1.45, 'total_flos': 5181483259184400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 57357, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 236173, 'train_mem_gpu_alloc_delta': 2228408320, 'train_mem_cpu_peaked_delta': 746146, 'train_mem_gpu_peaked_delta': 5410927616})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, batch size = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 09:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>1.249580</td>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.716956</td>\n",
       "      <td>0.827427</td>\n",
       "      <td>0.792432</td>\n",
       "      <td>3.457400</td>\n",
       "      <td>440.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.112400</td>\n",
       "      <td>1.029430</td>\n",
       "      <td>0.776756</td>\n",
       "      <td>0.759547</td>\n",
       "      <td>0.701961</td>\n",
       "      <td>0.827427</td>\n",
       "      <td>0.783279</td>\n",
       "      <td>3.456900</td>\n",
       "      <td>440.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.930210</td>\n",
       "      <td>0.808273</td>\n",
       "      <td>0.780451</td>\n",
       "      <td>0.762115</td>\n",
       "      <td>0.799692</td>\n",
       "      <td>0.807169</td>\n",
       "      <td>3.459800</td>\n",
       "      <td>440.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>1.166522</td>\n",
       "      <td>0.795798</td>\n",
       "      <td>0.774474</td>\n",
       "      <td>0.731507</td>\n",
       "      <td>0.822804</td>\n",
       "      <td>0.799274</td>\n",
       "      <td>3.456700</td>\n",
       "      <td>440.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>1.131894</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.781538</td>\n",
       "      <td>0.780338</td>\n",
       "      <td>0.782743</td>\n",
       "      <td>0.809564</td>\n",
       "      <td>3.457900</td>\n",
       "      <td>440.447000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.13170456683307183, metrics={'train_runtime': 567.7246, 'train_samples_per_second': 3.355, 'total_flos': 5181483259184400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 57445, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 289613, 'train_mem_gpu_alloc_delta': 2228408320, 'train_mem_cpu_peaked_delta': 1537354099, 'train_mem_gpu_peaked_delta': 1374734336})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, Alternate batch size\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args.per_device_train_batch_size = 16\n",
    "training_args.per_device_eval_batch_size = 54\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Apply Models with Preprocessed Data\n",
    "\n",
    "We observe that the Models with Proprocessed Data perform generally worse than without preprocessing.\n",
    "\n",
    "TO-DO: Log Performance Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - DistillBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0592cd25da8d41558bfe64b1763d88b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7bd47d8fe945ffbd18cdf6f5e15106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset_prc.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 02:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.436300</td>\n",
       "      <td>0.448120</td>\n",
       "      <td>0.810243</td>\n",
       "      <td>0.774747</td>\n",
       "      <td>0.783912</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>0.804521</td>\n",
       "      <td>1.478600</td>\n",
       "      <td>1030.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.448849</td>\n",
       "      <td>0.812213</td>\n",
       "      <td>0.774448</td>\n",
       "      <td>0.793215</td>\n",
       "      <td>0.756549</td>\n",
       "      <td>0.805048</td>\n",
       "      <td>1.480800</td>\n",
       "      <td>1028.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.548614</td>\n",
       "      <td>0.801051</td>\n",
       "      <td>0.767460</td>\n",
       "      <td>0.764526</td>\n",
       "      <td>0.770416</td>\n",
       "      <td>0.797107</td>\n",
       "      <td>1.477300</td>\n",
       "      <td>1030.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.852207</td>\n",
       "      <td>0.766251</td>\n",
       "      <td>0.744253</td>\n",
       "      <td>0.697174</td>\n",
       "      <td>0.798151</td>\n",
       "      <td>0.770357</td>\n",
       "      <td>1.492700</td>\n",
       "      <td>1020.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.936538</td>\n",
       "      <td>0.786605</td>\n",
       "      <td>0.755087</td>\n",
       "      <td>0.738938</td>\n",
       "      <td>0.771957</td>\n",
       "      <td>0.784720</td>\n",
       "      <td>1.476600</td>\n",
       "      <td>1031.411000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.3042660809564465, metrics={'train_runtime': 173.1884, 'train_samples_per_second': 11.0, 'total_flos': 636099377004000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 64899, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 240666, 'train_mem_gpu_alloc_delta': 819436032, 'train_mem_cpu_peaked_delta': 188545613, 'train_mem_gpu_peaked_delta': 315471360})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTILLBERT, BATCH SIZE = 16\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 02:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069300</td>\n",
       "      <td>0.905419</td>\n",
       "      <td>0.791202</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.746647</td>\n",
       "      <td>0.771957</td>\n",
       "      <td>0.788724</td>\n",
       "      <td>1.276000</td>\n",
       "      <td>1193.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.892546</td>\n",
       "      <td>0.792515</td>\n",
       "      <td>0.762048</td>\n",
       "      <td>0.745214</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.790860</td>\n",
       "      <td>1.272800</td>\n",
       "      <td>1196.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>1.032827</td>\n",
       "      <td>0.757715</td>\n",
       "      <td>0.733574</td>\n",
       "      <td>0.690217</td>\n",
       "      <td>0.782743</td>\n",
       "      <td>0.760937</td>\n",
       "      <td>1.275700</td>\n",
       "      <td>1193.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>1.182276</td>\n",
       "      <td>0.785292</td>\n",
       "      <td>0.753208</td>\n",
       "      <td>0.738166</td>\n",
       "      <td>0.768875</td>\n",
       "      <td>0.783179</td>\n",
       "      <td>1.285200</td>\n",
       "      <td>1185.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>1.242301</td>\n",
       "      <td>0.780696</td>\n",
       "      <td>0.752593</td>\n",
       "      <td>0.724679</td>\n",
       "      <td>0.782743</td>\n",
       "      <td>0.780959</td>\n",
       "      <td>1.273100</td>\n",
       "      <td>1196.322000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.07443335387095107, metrics={'train_runtime': 121.2532, 'train_samples_per_second': 7.876, 'total_flos': 636099377004000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59101, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 204291, 'train_mem_gpu_alloc_delta': 539094016, 'train_mem_cpu_peaked_delta': 188264287, 'train_mem_gpu_peaked_delta': 628525568})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTILLBERT, BATCH SIZE = 32\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 01:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>1.275790</td>\n",
       "      <td>0.782009</td>\n",
       "      <td>0.752608</td>\n",
       "      <td>0.728716</td>\n",
       "      <td>0.778120</td>\n",
       "      <td>0.781509</td>\n",
       "      <td>1.331600</td>\n",
       "      <td>1143.734000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>1.290219</td>\n",
       "      <td>0.779383</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.730486</td>\n",
       "      <td>0.764253</td>\n",
       "      <td>0.777435</td>\n",
       "      <td>1.235300</td>\n",
       "      <td>1232.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>1.251553</td>\n",
       "      <td>0.773473</td>\n",
       "      <td>0.748725</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.791988</td>\n",
       "      <td>0.775857</td>\n",
       "      <td>1.231300</td>\n",
       "      <td>1236.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>1.280395</td>\n",
       "      <td>0.780039</td>\n",
       "      <td>0.746788</td>\n",
       "      <td>0.732938</td>\n",
       "      <td>0.761171</td>\n",
       "      <td>0.777611</td>\n",
       "      <td>1.231500</td>\n",
       "      <td>1236.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>1.396290</td>\n",
       "      <td>0.764938</td>\n",
       "      <td>0.743920</td>\n",
       "      <td>0.694259</td>\n",
       "      <td>0.801233</td>\n",
       "      <td>0.769609</td>\n",
       "      <td>1.228400</td>\n",
       "      <td>1239.831000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.03591794210175673, metrics={'train_runtime': 97.8277, 'train_samples_per_second': 4.907, 'total_flos': 636099377004000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59445, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 186790, 'train_mem_gpu_alloc_delta': 539094016, 'train_mem_cpu_peaked_delta': 606472, 'train_mem_gpu_peaked_delta': 1241171456})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTILLBERT, BATCH SIZE = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 02:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>1.480103</td>\n",
       "      <td>0.730138</td>\n",
       "      <td>0.724346</td>\n",
       "      <td>0.641330</td>\n",
       "      <td>0.832049</td>\n",
       "      <td>0.743256</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>1229.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>1.266279</td>\n",
       "      <td>0.789232</td>\n",
       "      <td>0.749805</td>\n",
       "      <td>0.758675</td>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.783042</td>\n",
       "      <td>1.237700</td>\n",
       "      <td>1230.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.226236</td>\n",
       "      <td>0.793828</td>\n",
       "      <td>0.744300</td>\n",
       "      <td>0.789292</td>\n",
       "      <td>0.704160</td>\n",
       "      <td>0.782286</td>\n",
       "      <td>1.231300</td>\n",
       "      <td>1236.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>1.400789</td>\n",
       "      <td>0.785292</td>\n",
       "      <td>0.745525</td>\n",
       "      <td>0.753145</td>\n",
       "      <td>0.738059</td>\n",
       "      <td>0.779212</td>\n",
       "      <td>1.235800</td>\n",
       "      <td>1232.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>1.602843</td>\n",
       "      <td>0.774130</td>\n",
       "      <td>0.742515</td>\n",
       "      <td>0.721980</td>\n",
       "      <td>0.764253</td>\n",
       "      <td>0.772859</td>\n",
       "      <td>1.232900</td>\n",
       "      <td>1235.304000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.048202242672668275, metrics={'train_runtime': 169.1632, 'train_samples_per_second': 11.261, 'total_flos': 636099377004000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58397, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 831562, 'train_mem_gpu_alloc_delta': 539094016, 'train_mem_cpu_peaked_delta': 188501782, 'train_mem_gpu_peaked_delta': 315471360})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DISTILLBERT, ALTERNATE BATCH SIZE\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = 16\n",
    "training_args.per_device_eval_batch_size = 64\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653304e54ac54702a90895fa370e8f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1ad757108d4cb2bece1bdfb94c7aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset_prc.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 05:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.493087</td>\n",
       "      <td>0.793828</td>\n",
       "      <td>0.769457</td>\n",
       "      <td>0.734923</td>\n",
       "      <td>0.807396</td>\n",
       "      <td>0.795574</td>\n",
       "      <td>2.947800</td>\n",
       "      <td>516.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.452807</td>\n",
       "      <td>0.820092</td>\n",
       "      <td>0.779032</td>\n",
       "      <td>0.817259</td>\n",
       "      <td>0.744222</td>\n",
       "      <td>0.810326</td>\n",
       "      <td>2.951000</td>\n",
       "      <td>516.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.363400</td>\n",
       "      <td>0.483221</td>\n",
       "      <td>0.805647</td>\n",
       "      <td>0.765079</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>0.797542</td>\n",
       "      <td>2.938300</td>\n",
       "      <td>518.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.798424</td>\n",
       "      <td>0.766540</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>0.795612</td>\n",
       "      <td>2.906900</td>\n",
       "      <td>523.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.859537</td>\n",
       "      <td>0.804334</td>\n",
       "      <td>0.767551</td>\n",
       "      <td>0.777251</td>\n",
       "      <td>0.758089</td>\n",
       "      <td>0.798381</td>\n",
       "      <td>2.950600</td>\n",
       "      <td>516.164000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.33023957664885234, metrics={'train_runtime': 327.3885, 'train_samples_per_second': 5.819, 'total_flos': 1040139684511200.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 64675, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 286788, 'train_mem_gpu_alloc_delta': 1337938944, 'train_mem_cpu_peaked_delta': 189042154, 'train_mem_gpu_peaked_delta': 622353408})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT, BATCH SIZE = 16\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT, BATCH SIZE = 32\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 03:08, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.116100</td>\n",
       "      <td>0.804013</td>\n",
       "      <td>0.793171</td>\n",
       "      <td>0.760820</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771957</td>\n",
       "      <td>0.790441</td>\n",
       "      <td>2.457400</td>\n",
       "      <td>619.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.847194</td>\n",
       "      <td>0.794485</td>\n",
       "      <td>0.761615</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.770416</td>\n",
       "      <td>0.791387</td>\n",
       "      <td>2.448300</td>\n",
       "      <td>622.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.975983</td>\n",
       "      <td>0.764281</td>\n",
       "      <td>0.745209</td>\n",
       "      <td>0.690789</td>\n",
       "      <td>0.808937</td>\n",
       "      <td>0.770029</td>\n",
       "      <td>2.445900</td>\n",
       "      <td>622.666000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.917360</td>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.753799</td>\n",
       "      <td>0.743628</td>\n",
       "      <td>0.764253</td>\n",
       "      <td>0.784300</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>622.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>1.022981</td>\n",
       "      <td>0.783322</td>\n",
       "      <td>0.760174</td>\n",
       "      <td>0.719395</td>\n",
       "      <td>0.805855</td>\n",
       "      <td>0.786223</td>\n",
       "      <td>2.440500</td>\n",
       "      <td>624.041000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.08004579488188028, metrics={'train_runtime': 188.8364, 'train_samples_per_second': 2.542, 'total_flos': 1040139684511200.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 60173, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 236476, 'train_mem_gpu_alloc_delta': 879156736, 'train_mem_cpu_peaked_delta': 720571, 'train_mem_gpu_peaked_delta': 2460931584})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT, BATCH SIZE = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 05:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>1.305586</td>\n",
       "      <td>0.741300</td>\n",
       "      <td>0.730874</td>\n",
       "      <td>0.656442</td>\n",
       "      <td>0.824345</td>\n",
       "      <td>0.751990</td>\n",
       "      <td>2.443400</td>\n",
       "      <td>623.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>0.845192</td>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.749175</td>\n",
       "      <td>0.806394</td>\n",
       "      <td>0.699538</td>\n",
       "      <td>0.787412</td>\n",
       "      <td>2.434900</td>\n",
       "      <td>625.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1.164245</td>\n",
       "      <td>0.790545</td>\n",
       "      <td>0.757045</td>\n",
       "      <td>0.748494</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>0.787359</td>\n",
       "      <td>2.448800</td>\n",
       "      <td>621.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>1.418789</td>\n",
       "      <td>0.774787</td>\n",
       "      <td>0.747237</td>\n",
       "      <td>0.716102</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.775612</td>\n",
       "      <td>2.448500</td>\n",
       "      <td>622.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.449569</td>\n",
       "      <td>0.787919</td>\n",
       "      <td>0.753998</td>\n",
       "      <td>0.745482</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.784674</td>\n",
       "      <td>2.440300</td>\n",
       "      <td>624.101000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.07174895955762994, metrics={'train_runtime': 318.747, 'train_samples_per_second': 5.977, 'total_flos': 1040139684511200.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59429, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 287324, 'train_mem_gpu_alloc_delta': 880723456, 'train_mem_cpu_peaked_delta': 188964243, 'train_mem_gpu_peaked_delta': 622353408})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT, ALTERNATE BATCH SIZE\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = 16\n",
    "training_args.per_device_eval_batch_size = 64\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 - RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cc087995684d169ad0c9c5a73aef9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc82b7f90824ae7bdc36f26419fd14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'roberta-base'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset_prc.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 04:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.478200</td>\n",
       "      <td>0.653095</td>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.742895</td>\n",
       "      <td>0.650463</td>\n",
       "      <td>0.865948</td>\n",
       "      <td>0.760205</td>\n",
       "      <td>2.583700</td>\n",
       "      <td>589.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.536218</td>\n",
       "      <td>0.764938</td>\n",
       "      <td>0.638384</td>\n",
       "      <td>0.926686</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.729149</td>\n",
       "      <td>2.509700</td>\n",
       "      <td>606.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.453600</td>\n",
       "      <td>0.457539</td>\n",
       "      <td>0.812213</td>\n",
       "      <td>0.774448</td>\n",
       "      <td>0.793215</td>\n",
       "      <td>0.756549</td>\n",
       "      <td>0.805048</td>\n",
       "      <td>2.501100</td>\n",
       "      <td>608.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.513900</td>\n",
       "      <td>0.497330</td>\n",
       "      <td>0.803677</td>\n",
       "      <td>0.766224</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.755008</td>\n",
       "      <td>0.797412</td>\n",
       "      <td>2.629900</td>\n",
       "      <td>579.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.379800</td>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.815496</td>\n",
       "      <td>0.779608</td>\n",
       "      <td>0.793930</td>\n",
       "      <td>0.765794</td>\n",
       "      <td>0.809098</td>\n",
       "      <td>2.595400</td>\n",
       "      <td>586.798000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.4680079192314248, metrics={'train_runtime': 282.5954, 'train_samples_per_second': 6.741, 'total_flos': 1047559746114000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59470, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 282932, 'train_mem_gpu_alloc_delta': 1502477824, 'train_mem_cpu_peaked_delta': 310236475, 'train_mem_gpu_peaked_delta': 562674688})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROBERTA, BATCH SIZE = 16\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 03:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.293100</td>\n",
       "      <td>0.476329</td>\n",
       "      <td>0.824688</td>\n",
       "      <td>0.784851</td>\n",
       "      <td>0.822635</td>\n",
       "      <td>0.750385</td>\n",
       "      <td>0.815124</td>\n",
       "      <td>2.044400</td>\n",
       "      <td>744.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.333700</td>\n",
       "      <td>0.488231</td>\n",
       "      <td>0.820749</td>\n",
       "      <td>0.780723</td>\n",
       "      <td>0.815436</td>\n",
       "      <td>0.748844</td>\n",
       "      <td>0.811493</td>\n",
       "      <td>2.040700</td>\n",
       "      <td>746.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.572875</td>\n",
       "      <td>0.789232</td>\n",
       "      <td>0.758101</td>\n",
       "      <td>0.741888</td>\n",
       "      <td>0.775039</td>\n",
       "      <td>0.787405</td>\n",
       "      <td>2.057800</td>\n",
       "      <td>740.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.372300</td>\n",
       "      <td>0.706005</td>\n",
       "      <td>0.750492</td>\n",
       "      <td>0.741497</td>\n",
       "      <td>0.663825</td>\n",
       "      <td>0.839753</td>\n",
       "      <td>0.761982</td>\n",
       "      <td>2.041100</td>\n",
       "      <td>746.153000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.555090</td>\n",
       "      <td>0.799081</td>\n",
       "      <td>0.769925</td>\n",
       "      <td>0.751836</td>\n",
       "      <td>0.788906</td>\n",
       "      <td>0.797771</td>\n",
       "      <td>2.040300</td>\n",
       "      <td>746.467000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.32719765533327433, metrics={'train_runtime': 214.3332, 'train_samples_per_second': 4.456, 'total_flos': 1047559746114000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58933, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 251733, 'train_mem_gpu_alloc_delta': 999118848, 'train_mem_cpu_peaked_delta': 309836043, 'train_mem_gpu_peaked_delta': 1090786304})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROBERTA, BATCH SIZE = 32\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 02:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.554233</td>\n",
       "      <td>0.796454</td>\n",
       "      <td>0.771386</td>\n",
       "      <td>0.739745</td>\n",
       "      <td>0.805855</td>\n",
       "      <td>0.797664</td>\n",
       "      <td>2.141800</td>\n",
       "      <td>711.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.580534</td>\n",
       "      <td>0.808930</td>\n",
       "      <td>0.771046</td>\n",
       "      <td>0.787781</td>\n",
       "      <td>0.755008</td>\n",
       "      <td>0.801989</td>\n",
       "      <td>2.143800</td>\n",
       "      <td>710.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.618453</td>\n",
       "      <td>0.803677</td>\n",
       "      <td>0.775019</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.793529</td>\n",
       "      <td>0.802371</td>\n",
       "      <td>2.155000</td>\n",
       "      <td>706.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.606731</td>\n",
       "      <td>0.806960</td>\n",
       "      <td>0.770312</td>\n",
       "      <td>0.781300</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.800868</td>\n",
       "      <td>2.148300</td>\n",
       "      <td>708.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.688988</td>\n",
       "      <td>0.765594</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.691601</td>\n",
       "      <td>0.812018</td>\n",
       "      <td>0.771570</td>\n",
       "      <td>2.139900</td>\n",
       "      <td>711.709000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.22710321297248204, metrics={'train_runtime': 174.2404, 'train_samples_per_second': 2.755, 'total_flos': 1047559746114000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59069, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 236061, 'train_mem_gpu_alloc_delta': 999118848, 'train_mem_cpu_peaked_delta': 663370, 'train_mem_gpu_peaked_delta': 2127685632})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROBERTA, BATCH SIZE = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 04:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.735391</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>0.641055</td>\n",
       "      <td>0.861325</td>\n",
       "      <td>0.751601</td>\n",
       "      <td>2.143300</td>\n",
       "      <td>710.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.841780</td>\n",
       "      <td>0.778726</td>\n",
       "      <td>0.751658</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.785824</td>\n",
       "      <td>0.779640</td>\n",
       "      <td>2.140600</td>\n",
       "      <td>711.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.139900</td>\n",
       "      <td>0.657773</td>\n",
       "      <td>0.782666</td>\n",
       "      <td>0.757509</td>\n",
       "      <td>0.722067</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.784461</td>\n",
       "      <td>2.142700</td>\n",
       "      <td>710.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.850542</td>\n",
       "      <td>0.753775</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>0.681217</td>\n",
       "      <td>0.793529</td>\n",
       "      <td>0.758892</td>\n",
       "      <td>2.149400</td>\n",
       "      <td>708.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.261900</td>\n",
       "      <td>0.808784</td>\n",
       "      <td>0.782009</td>\n",
       "      <td>0.749245</td>\n",
       "      <td>0.734815</td>\n",
       "      <td>0.764253</td>\n",
       "      <td>0.779724</td>\n",
       "      <td>2.141700</td>\n",
       "      <td>711.129000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.20245603380866564, metrics={'train_runtime': 276.5422, 'train_samples_per_second': 6.889, 'total_flos': 1047559746114000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58701, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 288437, 'train_mem_gpu_alloc_delta': 999379968, 'train_mem_cpu_peaked_delta': 310165287, 'train_mem_gpu_peaked_delta': 562674688})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROBERTA, ALTERNATE BATCH SIZE\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = 16\n",
    "training_args.per_device_eval_batch_size = 64\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 - XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5094cd135749b2a5fd87ecac862d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c949c3b72744e8daa77b1200d803ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'xlm-roberta-base'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset_prc.map(tokenize, batched=True, batch_size=None)\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 06:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.533284</td>\n",
       "      <td>0.776100</td>\n",
       "      <td>0.695807</td>\n",
       "      <td>0.826271</td>\n",
       "      <td>0.600924</td>\n",
       "      <td>0.753551</td>\n",
       "      <td>2.847900</td>\n",
       "      <td>534.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.550574</td>\n",
       "      <td>0.751806</td>\n",
       "      <td>0.673010</td>\n",
       "      <td>0.767258</td>\n",
       "      <td>0.599384</td>\n",
       "      <td>0.732186</td>\n",
       "      <td>2.856800</td>\n",
       "      <td>533.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.603400</td>\n",
       "      <td>0.562373</td>\n",
       "      <td>0.789232</td>\n",
       "      <td>0.730025</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.668721</td>\n",
       "      <td>0.773720</td>\n",
       "      <td>2.849800</td>\n",
       "      <td>534.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>0.501632</td>\n",
       "      <td>0.793171</td>\n",
       "      <td>0.754482</td>\n",
       "      <td>0.763407</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.787069</td>\n",
       "      <td>2.922000</td>\n",
       "      <td>521.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.497789</td>\n",
       "      <td>0.795798</td>\n",
       "      <td>0.749799</td>\n",
       "      <td>0.784512</td>\n",
       "      <td>0.718028</td>\n",
       "      <td>0.785787</td>\n",
       "      <td>2.845900</td>\n",
       "      <td>535.154000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.5438121632953954, metrics={'train_runtime': 395.9671, 'train_samples_per_second': 4.811, 'total_flos': 2489143918627800.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 63931, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 286929, 'train_mem_gpu_alloc_delta': 3342390784, 'train_mem_cpu_peaked_delta': 1537412835, 'train_mem_gpu_peaked_delta': 771453440})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, BATCH SIZE = 16\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='955' max='955' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [955/955 04:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.467429</td>\n",
       "      <td>0.791858</td>\n",
       "      <td>0.725065</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.772835</td>\n",
       "      <td>2.423100</td>\n",
       "      <td>628.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.392600</td>\n",
       "      <td>0.489939</td>\n",
       "      <td>0.797768</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.784529</td>\n",
       "      <td>2.410800</td>\n",
       "      <td>631.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>0.590386</td>\n",
       "      <td>0.783979</td>\n",
       "      <td>0.746728</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.747304</td>\n",
       "      <td>0.779258</td>\n",
       "      <td>2.409300</td>\n",
       "      <td>632.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.514511</td>\n",
       "      <td>0.785292</td>\n",
       "      <td>0.745129</td>\n",
       "      <td>0.753943</td>\n",
       "      <td>0.736518</td>\n",
       "      <td>0.779014</td>\n",
       "      <td>2.412400</td>\n",
       "      <td>631.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.509533</td>\n",
       "      <td>0.781353</td>\n",
       "      <td>0.738824</td>\n",
       "      <td>0.752396</td>\n",
       "      <td>0.725732</td>\n",
       "      <td>0.774193</td>\n",
       "      <td>2.412000</td>\n",
       "      <td>631.424000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=955, training_loss=0.4450613478715507, metrics={'train_runtime': 264.728, 'train_samples_per_second': 3.607, 'total_flos': 2489143918627800.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 58669, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 252742, 'train_mem_gpu_alloc_delta': 2225297408, 'train_mem_cpu_peaked_delta': 1537023863, 'train_mem_gpu_peaked_delta': 1149223424})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, BATCH SIZE = 32\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 03:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.515022</td>\n",
       "      <td>0.787919</td>\n",
       "      <td>0.748638</td>\n",
       "      <td>0.756289</td>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.781897</td>\n",
       "      <td>2.303300</td>\n",
       "      <td>661.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.496408</td>\n",
       "      <td>0.795798</td>\n",
       "      <td>0.753370</td>\n",
       "      <td>0.776144</td>\n",
       "      <td>0.731895</td>\n",
       "      <td>0.787572</td>\n",
       "      <td>2.303200</td>\n",
       "      <td>661.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.403400</td>\n",
       "      <td>0.494306</td>\n",
       "      <td>0.799737</td>\n",
       "      <td>0.759274</td>\n",
       "      <td>0.778317</td>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.792195</td>\n",
       "      <td>2.312700</td>\n",
       "      <td>658.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.404300</td>\n",
       "      <td>0.623651</td>\n",
       "      <td>0.774130</td>\n",
       "      <td>0.754986</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.816641</td>\n",
       "      <td>0.779602</td>\n",
       "      <td>2.304300</td>\n",
       "      <td>660.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.488627</td>\n",
       "      <td>0.791202</td>\n",
       "      <td>0.750784</td>\n",
       "      <td>0.763955</td>\n",
       "      <td>0.738059</td>\n",
       "      <td>0.784361</td>\n",
       "      <td>2.304800</td>\n",
       "      <td>660.792000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=480, training_loss=0.38764378676811856, metrics={'train_runtime': 188.2988, 'train_samples_per_second': 2.549, 'total_flos': 2489143918627800.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59301, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 236446, 'train_mem_gpu_alloc_delta': 2225297408, 'train_mem_cpu_peaked_delta': 673214, 'train_mem_gpu_peaked_delta': 2267061248})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, BATCH SIZE = 64\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 64\n",
    "training_args.per_device_train_batch_size = batch_size\n",
    "training_args.per_device_eval_batch_size = batch_size\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 06:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.531931</td>\n",
       "      <td>0.784636</td>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.759289</td>\n",
       "      <td>0.724191</td>\n",
       "      <td>0.776855</td>\n",
       "      <td>2.300700</td>\n",
       "      <td>661.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.580200</td>\n",
       "      <td>0.602119</td>\n",
       "      <td>0.692055</td>\n",
       "      <td>0.462772</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.311248</td>\n",
       "      <td>0.643038</td>\n",
       "      <td>2.302200</td>\n",
       "      <td>661.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.543283</td>\n",
       "      <td>0.789888</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.798548</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.775482</td>\n",
       "      <td>2.301900</td>\n",
       "      <td>661.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>0.558497</td>\n",
       "      <td>0.784636</td>\n",
       "      <td>0.712785</td>\n",
       "      <td>0.825558</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.764360</td>\n",
       "      <td>2.306800</td>\n",
       "      <td>660.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.560158</td>\n",
       "      <td>0.798424</td>\n",
       "      <td>0.747740</td>\n",
       "      <td>0.801056</td>\n",
       "      <td>0.701079</td>\n",
       "      <td>0.785894</td>\n",
       "      <td>2.302700</td>\n",
       "      <td>661.393000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.3868970046206096, metrics={'train_runtime': 414.6066, 'train_samples_per_second': 4.595, 'total_flos': 2489143918627800.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 59069, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 879873, 'train_mem_gpu_alloc_delta': 2225297408, 'train_mem_cpu_peaked_delta': 1537350011, 'train_mem_gpu_peaked_delta': 771453440})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLM-ROBERTA, ALTERNATE BATCH SIZE\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "batch_size = 32\n",
    "training_args.per_device_train_batch_size = 16\n",
    "training_args.per_device_eval_batch_size = 64\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Hyperparameters Tuning\n",
    "\n",
    "In this section, I will focus solely on BERT-Base, no text preprocessing because it achieves the best accuracy so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'bert-base-uncased'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tweets_encoded = tweets_dataset.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'text', 'token_type_ids'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'label', 'text', 'token_type_ids'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 06:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.461868</td>\n",
       "      <td>0.804990</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.747887</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.806688</td>\n",
       "      <td>3.401700</td>\n",
       "      <td>447.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.843729</td>\n",
       "      <td>0.803306</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.748844</td>\n",
       "      <td>0.831516</td>\n",
       "      <td>3.400500</td>\n",
       "      <td>447.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.545667</td>\n",
       "      <td>0.822718</td>\n",
       "      <td>0.794207</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.802773</td>\n",
       "      <td>0.820151</td>\n",
       "      <td>3.440300</td>\n",
       "      <td>442.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.802079</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>0.783259</td>\n",
       "      <td>0.760522</td>\n",
       "      <td>0.807396</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>3.397800</td>\n",
       "      <td>448.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.850523</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.798732</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>0.815635</td>\n",
       "      <td>3.397000</td>\n",
       "      <td>448.343000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.27335793571131123, metrics={'train_runtime': 411.0058, 'train_samples_per_second': 4.635, 'total_flos': 1680225644210400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 65011, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 287772, 'train_mem_gpu_alloc_delta': 1322197504, 'train_mem_cpu_peaked_delta': 189040583, 'train_mem_gpu_peaked_delta': 1082978816})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1905' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1905/1905 07:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.461868</td>\n",
       "      <td>0.804990</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.747887</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.806688</td>\n",
       "      <td>4.885500</td>\n",
       "      <td>311.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.843729</td>\n",
       "      <td>0.803306</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>0.748844</td>\n",
       "      <td>0.831516</td>\n",
       "      <td>4.453100</td>\n",
       "      <td>342.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.545667</td>\n",
       "      <td>0.822718</td>\n",
       "      <td>0.794207</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.802773</td>\n",
       "      <td>0.820151</td>\n",
       "      <td>4.416500</td>\n",
       "      <td>344.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.802079</td>\n",
       "      <td>0.809586</td>\n",
       "      <td>0.783259</td>\n",
       "      <td>0.760522</td>\n",
       "      <td>0.807396</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>4.609500</td>\n",
       "      <td>330.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.850523</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.798732</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>0.815635</td>\n",
       "      <td>4.745300</td>\n",
       "      <td>320.946000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1905, training_loss=0.27335793571131123, metrics={'train_runtime': 459.9487, 'train_samples_per_second': 4.142, 'total_flos': 1680225644210400.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 104562, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 202307, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 295377, 'train_mem_gpu_alloc_delta': 1321312768, 'train_mem_cpu_peaked_delta': 189038877, 'train_mem_gpu_peaked_delta': 1083695616})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_encoded.set_format(\"torch\",\n",
    "                          columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=5,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                      \n",
    "    args=training_args,                 \n",
    "    train_dataset=tweets_encoded[\"train\"],\n",
    "    eval_dataset=tweets_encoded[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.7/site-packages (2.6.0)\n",
      "Requirement already satisfied: alembic in /opt/conda/lib/python3.7/site-packages (from optuna) (1.5.8)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from optuna) (4.49.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (20.9)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from optuna) (4.8.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (1.3.23)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (1.5.4)\n",
      "Requirement already satisfied: numpy<1.20.0 in /opt/conda/lib/python3.7/site-packages (from optuna) (1.19.5)\n",
      "Requirement already satisfied: cliff in /opt/conda/lib/python3.7/site-packages (from optuna) (3.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: python-editor>=0.3 in /opt/conda/lib/python3.7/site-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->optuna) (1.1.4)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (2.0.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (5.5.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (5.3.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna) (1.5.0)\n",
      "Requirement already satisfied: colorama>=0.3.7 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.6.0->cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.6.0->cmd2>=1.0.0->cliff->optuna) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from PrettyTable>=0.7.2->cliff->optuna) (49.6.0.post20210108)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil->alembic->optuna) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = tweets_encoded[\"train\"].shard(index=1, num_shards=5)\n",
    "eval_subset = tweets_encoded[\"validation\"].shard(index=1, num_shards=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "\u001b[32m[I 2021-04-04 22:16:23,536]\u001b[0m A new study created in memory with name: no-name-728efd34-06c5-48ea-a20c-d8a77c6abaf3\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [306/306 00:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.663980</td>\n",
       "      <td>0.596721</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.631043</td>\n",
       "      <td>0.938500</td>\n",
       "      <td>324.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.590500</td>\n",
       "      <td>0.582148</td>\n",
       "      <td>0.718033</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.722719</td>\n",
       "      <td>0.955300</td>\n",
       "      <td>319.258000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-04 22:17:14,005]\u001b[0m Trial 0 finished with value: 3.546978407738381 and parameters: {'learning_rate': 1.9794712643338832e-06, 'num_train_epochs': 2, 'seed': 1, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 3.546978407738381.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='459' max='459' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [459/459 01:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.651523</td>\n",
       "      <td>0.583607</td>\n",
       "      <td>0.646240</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.618585</td>\n",
       "      <td>1.103800</td>\n",
       "      <td>276.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.603900</td>\n",
       "      <td>0.529530</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.739052</td>\n",
       "      <td>0.957200</td>\n",
       "      <td>318.649000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>0.499233</td>\n",
       "      <td>0.773770</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.810606</td>\n",
       "      <td>0.778135</td>\n",
       "      <td>0.966100</td>\n",
       "      <td>315.696000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-04 22:18:28,643]\u001b[0m Trial 1 finished with value: 3.8273049697607835 and parameters: {'learning_rate': 3.703407111165308e-06, 'num_train_epochs': 3, 'seed': 30, 'per_device_train_batch_size': 8}. Best is trial 1 with value: 3.8273049697607835.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.783200</td>\n",
       "      <td>0.765010</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>323.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.706300</td>\n",
       "      <td>0.752150</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.952100</td>\n",
       "      <td>320.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.741100</td>\n",
       "      <td>0.732333</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>322.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.747200</td>\n",
       "      <td>0.701996</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497110</td>\n",
       "      <td>0.941200</td>\n",
       "      <td>324.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.681100</td>\n",
       "      <td>0.668886</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.498008</td>\n",
       "      <td>0.938300</td>\n",
       "      <td>325.042000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-04 22:19:40,965]\u001b[0m Trial 2 finished with value: 1.4176658639204835 and parameters: {'learning_rate': 3.353320795683662e-06, 'num_train_epochs': 5, 'seed': 2, 'per_device_train_batch_size': 64}. Best is trial 1 with value: 3.8273049697607835.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1220' max='1220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1220/1220 02:20, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>0.452045</td>\n",
       "      <td>0.813115</td>\n",
       "      <td>0.792727</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.814613</td>\n",
       "      <td>0.949100</td>\n",
       "      <td>321.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.563500</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.813115</td>\n",
       "      <td>0.801394</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.819999</td>\n",
       "      <td>0.949100</td>\n",
       "      <td>321.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.789173</td>\n",
       "      <td>0.822951</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.823283</td>\n",
       "      <td>0.963500</td>\n",
       "      <td>316.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.833360</td>\n",
       "      <td>0.829508</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828166</td>\n",
       "      <td>0.954400</td>\n",
       "      <td>319.584000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-04 22:22:06,784]\u001b[0m Trial 3 finished with value: 4.075943864815264 and parameters: {'learning_rate': 3.0926228561475635e-05, 'num_train_epochs': 4, 'seed': 32, 'per_device_train_batch_size': 4}. Best is trial 3 with value: 4.075943864815264.\u001b[0m\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='306' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [306/306 00:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.554254</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.729097</td>\n",
       "      <td>0.652695</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.745249</td>\n",
       "      <td>0.949200</td>\n",
       "      <td>321.317000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.591700</td>\n",
       "      <td>0.459070</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803950</td>\n",
       "      <td>0.936400</td>\n",
       "      <td>325.713000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-04 22:22:57,017]\u001b[0m Trial 4 finished with value: 3.958456420017459 and parameters: {'learning_rate': 1.3514222297819783e-05, 'num_train_epochs': 2, 'seed': 3, 'per_device_train_batch_size': 8}. Best is trial 3 with value: 4.075943864815264.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "set_cuda_seed()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',         \n",
    "    num_train_epochs=3,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,   \n",
    "    warmup_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',       \n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model_init=model_init, \n",
    "                  args=training_args,\n",
    "                  compute_metrics=compute_metrics, \n",
    "                  train_dataset=train_subset,\n",
    "                  eval_dataset=eval_subset)\n",
    "\n",
    "best_run = trainer.hyperparameter_search(n_trials=5, \n",
    "                                         direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='3', objective=4.075943864815264, hyperparameters={'learning_rate': 3.0926228561475635e-05, 'num_train_epochs': 4, 'seed': 32, 'per_device_train_batch_size': 4})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='6092' max='6092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6092/6092 11:45, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.400800</td>\n",
       "      <td>0.468558</td>\n",
       "      <td>0.832567</td>\n",
       "      <td>0.790812</td>\n",
       "      <td>0.845614</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>0.820997</td>\n",
       "      <td>4.881300</td>\n",
       "      <td>312.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>0.474542</td>\n",
       "      <td>0.843729</td>\n",
       "      <td>0.809295</td>\n",
       "      <td>0.843072</td>\n",
       "      <td>0.778120</td>\n",
       "      <td>0.835284</td>\n",
       "      <td>4.731100</td>\n",
       "      <td>321.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.806386</td>\n",
       "      <td>0.824688</td>\n",
       "      <td>0.797574</td>\n",
       "      <td>0.785075</td>\n",
       "      <td>0.810478</td>\n",
       "      <td>0.822859</td>\n",
       "      <td>4.878200</td>\n",
       "      <td>312.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.885972</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.809672</td>\n",
       "      <td>0.799692</td>\n",
       "      <td>0.830052</td>\n",
       "      <td>4.479600</td>\n",
       "      <td>339.987000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6092, training_loss=0.41640878909020435, metrics={'train_runtime': 705.9342, 'train_samples_per_second': 8.63, 'total_flos': 1344180515368320.0, 'epoch': 4.0, 'train_mem_cpu_alloc_delta': 1138250, 'train_mem_gpu_alloc_delta': -522240, 'train_mem_cpu_peaked_delta': 189147493, 'train_mem_gpu_peaked_delta': 439266816})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, value in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, key, value)\n",
    "\n",
    "trainer.train_dataset = tweets_encoded[\"train\"]\n",
    "trainer.eval_dataset = tweets_encoded[\"validation\"]\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207485226526592"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['eval_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "\n",
    "## 2.5. Choose a Final Model and Evaluate This Model on Multiple Train-Eval Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-814707f59a0766b4/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-814707f59a0766b4/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1ff17c07174dec830ac7ea387fa80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc271faa04e2439ca49f95f39a2e56d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='762' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [762/762 02:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.468578</td>\n",
       "      <td>0.822718</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.772603</td>\n",
       "      <td>0.844311</td>\n",
       "      <td>0.825080</td>\n",
       "      <td>3.676300</td>\n",
       "      <td>414.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.397790</td>\n",
       "      <td>0.837163</td>\n",
       "      <td>0.815750</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.821856</td>\n",
       "      <td>0.835490</td>\n",
       "      <td>3.675400</td>\n",
       "      <td>414.373000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-84c7d1ef6fd0621d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-84c7d1ef6fd0621d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9614ed3feb48dfb86916421bcaa4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff8b020a8a44f699d9ce54044c04afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='762' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [762/762 02:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.262446</td>\n",
       "      <td>0.900197</td>\n",
       "      <td>0.873544</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.844051</td>\n",
       "      <td>0.891504</td>\n",
       "      <td>3.142200</td>\n",
       "      <td>484.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.318142</td>\n",
       "      <td>0.892318</td>\n",
       "      <td>0.865794</td>\n",
       "      <td>0.881667</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.885840</td>\n",
       "      <td>3.140900</td>\n",
       "      <td>484.896000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-51a85ca0d7380bc0/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-51a85ca0d7380bc0/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e338c469e84a69b8a14edf19e39b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9fb2bc3f5b49fdbeab02db2c681484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='762' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [762/762 02:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.563911</td>\n",
       "      <td>0.883125</td>\n",
       "      <td>0.855049</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.844051</td>\n",
       "      <td>0.877076</td>\n",
       "      <td>3.141100</td>\n",
       "      <td>484.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247900</td>\n",
       "      <td>0.529141</td>\n",
       "      <td>0.871963</td>\n",
       "      <td>0.846093</td>\n",
       "      <td>0.831008</td>\n",
       "      <td>0.861736</td>\n",
       "      <td>0.870380</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>484.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-9f73ad38e72f853c/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-9f73ad38e72f853c/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5985dc61c1fe4d8cab8e3976a3f7e097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a41858332b40f587bc193ca95be76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='762' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [762/762 02:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.856954</td>\n",
       "      <td>0.875246</td>\n",
       "      <td>0.833040</td>\n",
       "      <td>0.918605</td>\n",
       "      <td>0.762058</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>3.140000</td>\n",
       "      <td>485.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.595805</td>\n",
       "      <td>0.854235</td>\n",
       "      <td>0.828173</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.860129</td>\n",
       "      <td>0.855148</td>\n",
       "      <td>3.141600</td>\n",
       "      <td>484.784000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-1aeb2af55132318d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-1aeb2af55132318d/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33f7c0b2205499faf281e72481cd8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95bfdcb839a4c909c24ce896d9d2b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='762' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [762/762 02:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.014512</td>\n",
       "      <td>0.862771</td>\n",
       "      <td>0.832934</td>\n",
       "      <td>0.828299</td>\n",
       "      <td>0.837621</td>\n",
       "      <td>0.858877</td>\n",
       "      <td>3.140400</td>\n",
       "      <td>484.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.641181</td>\n",
       "      <td>0.850952</td>\n",
       "      <td>0.823071</td>\n",
       "      <td>0.798790</td>\n",
       "      <td>0.848875</td>\n",
       "      <td>0.850630</td>\n",
       "      <td>3.143600</td>\n",
       "      <td>484.482000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-2bf927bae0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_rand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mavg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Average Accuracy is {avg_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "# BestRun(run_id='3', \n",
    "# objective=4.075943864815264, \n",
    "# hyperparameters={'learning_rate': 3.0926228561475635e-05, 'num_train_epochs': 4, \n",
    "# 'seed': 32, 'per_device_train_batch_size': 4})\n",
    "\n",
    "all_train_texts = train.text.to_list()\n",
    "all_train_labels = train.target.to_list()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'bert-base-uncased'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))\n",
    "\n",
    "accs = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    \n",
    "    seed = random.randint(0, 1000)\n",
    "\n",
    "    train_texts_rand, val_texts_rand, train_labels_rand, val_labels_rand = train_test_split(\n",
    "        all_train_texts, all_train_labels, \n",
    "        test_size=0.2, \n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    train_df_rand = pd.DataFrame(list(zip(train_texts_rand, train_labels_rand)),\n",
    "                                 columns =['text', 'label'])\n",
    "\n",
    "    val_df_rand = pd.DataFrame(list(zip(val_texts_rand, val_labels_rand)),\n",
    "                               columns =['text', 'label'])\n",
    "\n",
    "    train_df_rand.to_csv(os.path.join(data_path, 'train_df_rand.csv'), index=False)\n",
    "    val_df_rand.to_csv(os.path.join(data_path, 'val_df_rand.csv'), index=False)\n",
    "\n",
    "    tweets_dataset_rand = load_dataset('csv', data_files={'train': os.path.join(data_path, \n",
    "                                                                               'train_df_rand.csv'),\n",
    "                                                          'validation': os.path.join(data_path, \n",
    "                                                                                    'val_df_rand.csv')})\n",
    "    \n",
    "    tweets_encoded_rand = tweets_dataset_rand.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "    set_cuda_seed()\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',         \n",
    "        num_train_epochs=2,             \n",
    "        per_device_train_batch_size=16,  \n",
    "        per_device_eval_batch_size=64,   \n",
    "        warmup_steps=500,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        weight_decay=0.01,               \n",
    "        logging_dir='./logs',       \n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,                      \n",
    "        args=training_args,                 \n",
    "        train_dataset=tweets_encoded_rand[\"train\"],\n",
    "        eval_dataset=tweets_encoded_rand[\"validation\"],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    acc_rand = float(trainer.evaluate()['eval_accuracy'])\n",
    "    accs.append(acc_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy is 0.8613263296126068\n"
     ]
    }
   ],
   "source": [
    "avg_acc = np.mean(accs)\n",
    "print(f'Average Accuracy is {avg_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-9a637b196696e477/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-9a637b196696e477/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e1b6e7c1c145e1beb013909a37ef46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3831304c1374b7cb41ffd2e96c557fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='762' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [762/762 02:44, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>0.399743</td>\n",
       "      <td>0.835850</td>\n",
       "      <td>0.793729</td>\n",
       "      <td>0.815254</td>\n",
       "      <td>0.773312</td>\n",
       "      <td>0.826168</td>\n",
       "      <td>3.157800</td>\n",
       "      <td>482.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.402700</td>\n",
       "      <td>0.416613</td>\n",
       "      <td>0.827971</td>\n",
       "      <td>0.794992</td>\n",
       "      <td>0.774390</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>0.826229</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>484.874000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-07c20749a18048b5/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-07c20749a18048b5/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0c45689ac449f5a65088b101ef4399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9867f59092b241e8940534702817f5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='762' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [762/762 02:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.397562</td>\n",
       "      <td>0.829941</td>\n",
       "      <td>0.779199</td>\n",
       "      <td>0.829401</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.815199</td>\n",
       "      <td>3.139900</td>\n",
       "      <td>485.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.356700</td>\n",
       "      <td>0.414885</td>\n",
       "      <td>0.835850</td>\n",
       "      <td>0.802215</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.815113</td>\n",
       "      <td>0.832640</td>\n",
       "      <td>3.140100</td>\n",
       "      <td>485.022000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-452d86d612d7c014/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-452d86d612d7c014/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6146a0b526485a9ca263d9f2c302e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5cce2b568e499fa38d8f4027f7b714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='501' max='762' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [501/762 01:42 < 00:53, 4.87 it/s, Epoch 1.31/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.397562</td>\n",
       "      <td>0.829941</td>\n",
       "      <td>0.779199</td>\n",
       "      <td>0.829401</td>\n",
       "      <td>0.734727</td>\n",
       "      <td>0.815199</td>\n",
       "      <td>3.142100</td>\n",
       "      <td>484.713000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BestRun(run_id='3', \n",
    "# objective=4.075943864815264, \n",
    "# hyperparameters={'learning_rate': 3.0926228561475635e-05, 'num_train_epochs': 4, \n",
    "# 'seed': 32, 'per_device_train_batch_size': 4})\n",
    "\n",
    "all_train_texts = train.text.to_list()\n",
    "all_train_labels = train.target.to_list()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = 'bert-base-uncased'\n",
    "num_labels = 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    \n",
    "    seed = random.randint(0, 1000)\n",
    "\n",
    "    train_texts_rand, val_texts_rand, train_labels_rand, val_labels_rand = train_test_split(\n",
    "        all_train_texts, all_train_labels, \n",
    "        test_size=0.2, \n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    train_df_rand = pd.DataFrame(list(zip(train_texts_rand, train_labels_rand)),\n",
    "                                 columns =['text', 'label'])\n",
    "\n",
    "    val_df_rand = pd.DataFrame(list(zip(val_texts_rand, val_labels_rand)),\n",
    "                               columns =['text', 'label'])\n",
    "\n",
    "    train_df_rand.to_csv(os.path.join(data_path, 'train_df_rand.csv'), index=False)\n",
    "    val_df_rand.to_csv(os.path.join(data_path, 'val_df_rand.csv'), index=False)\n",
    "\n",
    "    tweets_dataset_rand = load_dataset('csv', data_files={'train': os.path.join(data_path, \n",
    "                                                                               'train_df_rand.csv'),\n",
    "                                                          'validation': os.path.join(data_path, \n",
    "                                                                                    'val_df_rand.csv')})\n",
    "    \n",
    "    tweets_encoded_rand = tweets_dataset_rand.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "    model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_name, num_labels=num_labels)\n",
    "         .to(device))\n",
    "    \n",
    "    transformers.set_seed(42)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',         \n",
    "        num_train_epochs=2,             \n",
    "        per_device_train_batch_size=16,  \n",
    "        per_device_eval_batch_size=64,   \n",
    "        warmup_steps=500,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        weight_decay=0.01,               \n",
    "        logging_dir='./logs',       \n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,                      \n",
    "        args=training_args,                 \n",
    "        train_dataset=tweets_encoded_rand[\"train\"],\n",
    "        eval_dataset=tweets_encoded_rand[\"validation\"],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    acc_rand = float(trainer.evaluate()['eval_accuracy'])\n",
    "    accs.append(acc_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /kaggle/working/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
